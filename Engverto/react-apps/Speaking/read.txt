import React, { useState, useEffect, useRef, useCallback } from "react";
import LiveTranscript from "./LiveTranscript";

const ConversationArea = ({ onConversationComplete }) => {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [messages, setMessages] = useState([]);
  const [currentTranscript, setCurrentTranscript] = useState("");
  const [startTime, setStartTime] = useState(null);
  const [hasTranscriptBeenHandled, setHasTranscriptBeenHandled] = useState(false);

  const recognitionRef = useRef(null);

  const apiKey = "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";

  const speak = useCallback((text) => {
    if (!window.speechSynthesis) return;

    const utterance = new SpeechSynthesisUtterance(text);
    window.speechSynthesis.cancel();
    window.speechSynthesis.speak(utterance);
  }, []);

  const handleTranscriptComplete = useCallback(async () => {
    console.log("Handling transcript:", currentTranscript);
    if (!currentTranscript || !isRecording) return;

    const userMessage = {
      role: "user",
      content: currentTranscript,
      timestamp: Date.now(),
    };

    setMessages((prev) => [...prev, userMessage]);
    setHasTranscriptBeenHandled(true);
    setCurrentTranscript("");
    

    const reply = await getAIResponse(userMessage.content, [...messages, userMessage]);

    const assistantMessage = {
      role: "assistant",
      content: reply,
      timestamp: Date.now(),
    };

    setMessages((prev) => [...prev, assistantMessage]);
    speak(reply);
  }, [currentTranscript, isRecording, messages, speak]);

  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      alert("Speech recognition is not supported in this browser.");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;

    recognition.onresult = (event) => {
      const latest = event.results[event.results.length - 1];
      if (latest.isFinal) {
        console.log("Final transcript:", latest[0].transcript.trim());
        setCurrentTranscript(latest[0].transcript.trim());
      }
    };

    recognition.onerror = (e) => {
      console.error("Speech recognition error:", e.error);
      setIsRecording(false);
    };

    recognitionRef.current = recognition;

    return () => {
      recognition.stop();
      window.speechSynthesis.cancel();
    };
  }, []);

  useEffect(() => {
    if (currentTranscript && isRecording) {
      const timeout = setTimeout(() => {
        handleTranscriptComplete();
      }, 1500);

      return () => clearTimeout(timeout);
    }
  }, [currentTranscript, isRecording, handleTranscriptComplete]);

  const startConversation = () => {
    setIsRecording(true);
    setMessages([]);
    setStartTime(Date.now());
    setCurrentTranscript("");
    setHasTranscriptBeenHandled(false);

    const welcome = {
      role: "assistant",
      content: "Hi, what would you like to talk about today?",
      timestamp: Date.now(),
    };

    setMessages([welcome]);
    recognitionRef.current?.start();
    speak(welcome.content);
  };

  const stopConversation = async () => {
    setIsRecording(false);
    setIsProcessing(true);
    recognitionRef.current?.stop();
    window.speechSynthesis.cancel();

    if (currentTranscript && !hasTranscriptBeenHandled) {
      const userMsg = {
        role: "user",
        content: currentTranscript,
        timestamp: Date.now(),
      };
      setMessages((prev) => [...prev, userMsg]);
      setCurrentTranscript("");
    }

    const feedback = await generateFeedback();
    onConversationComplete(feedback);
    setIsProcessing(false);
  };

  const getAIResponse = async (input, history) => {
    const formatted = history.map((msg) => ({ role: msg.role, content: msg.content }));

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content:
              "You are a friendly English conversation partner. Keep responses short and natural.",
          },
          ...formatted,
        ],
        max_tokens: 150,
      }),
    });

    const data = await response.json();
    return data?.choices?.[0]?.message?.content?.trim() || "Could you say that again?";
  };

  const generateFeedback = async () => {
    const userText = messages
      .filter((m) => m.role === "user")
      .map((m) => m.content)
      .join("\n");

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: "gpt-3.5-turbo",
        messages: [
          {
            role: "system",
            content: `You are an English teacher. Analyze this conversation and return:
            {
              "grammar": { "score": 85, "comments": [...] },
              "fluency": { "score": 80, "comments": [...] },
              "vocabulary": { "score": 78, "comments": [...] },
              "overallScore": 81,
              "summary": "..."
            }`,
          },
          { role: "user", content: userText },
        ],
        max_tokens: 1000,
      }),
    });

    const data = await response.json();
    try {
      const feedback = JSON.parse(data?.choices?.[0]?.message?.content);
      return {
        id: Date.now().toString(),
        title: `Conversation on ${new Date().toLocaleDateString()}`,
        messages,
        feedback,
        date: Date.now(),
        duration: startTime ? (Date.now() - startTime) / 1000 : 0,
      };
    } catch {
      return createMockFeedback();
    }
  };

  const createMockFeedback = () => {
    return {
      id: Date.now().toString(),
      title: `Conversation on ${new Date().toLocaleDateString()}`,
      messages,
      feedback: {
        grammar: { name: "Grammar", score: 80, comments: ["..."] },
        fluency: { name: "Fluency", score: 75, comments: ["..."] },
        vocabulary: { name: "Vocabulary", score: 78, comments: ["..."] },
        overallScore: 78,
        summary: "Mock feedback.",
      },
      date: Date.now(),
      duration: startTime ? (Date.now() - startTime) / 1000 : 0,
    };
  };

  return (
    <div className="space-y-4">
      <h2 className="text-2xl font-bold text-blue-700">Voice Conversation</h2>

      <div className="h-64 overflow-y-auto bg-gray-50 rounded p-3 space-y-3">
        {messages.map((msg, i) => (
          <div
            key={i}
            className={`rounded p-2 ${
              msg.role === "user" ? "bg-green-100 text-left" : "bg-blue-100 text-right"
            }`}
          >
            <p className="text-sm">
              <strong>{msg.role === "user" ? "You" : "AI"}:</strong> {msg.content}
            </p>
          </div>
        ))}

        {isRecording && currentTranscript && (
          <LiveTranscript
            text={currentTranscript}
            isRecording={isRecording}
            onTranscriptComplete={handleTranscriptComplete}
          />
        )}
      </div>

      <div className="flex justify-center gap-4">
        {!isRecording ? (
          <button
            onClick={startConversation}
            disabled={isProcessing}
            className="px-4 py-2 bg-green-600 text-white rounded hover:bg-green-700"
          >
            Start Conversation
          </button>
        ) : (
          <button
            onClick={stopConversation}
            className="px-4 py-2 bg-red-600 text-white rounded hover:bg-red-700"
          >
            Stop & Get Feedback
          </button>
        )}
      </div>

      {isProcessing && <p className="text-center text-blue-600">Analyzing... ‚è≥</p>}
    </div>
  );
};

export default ConversationArea;





‚úÖ 1. Add a Top Navbar Container
In your main layout file (probably App.js or your main page like Index.js), add this at the top:

jsx
Copy
Edit
<div className="w-full bg-gradient-to-r from-blue-600 to-blue-800 px-6 py-3 flex justify-between items-center shadow-md">
  <button className="text-white font-bold text-lg tracking-wide bg-white/10 hover:bg-white/20 px-4 py-2 rounded-lg transition-all duration-300 shadow-sm hover:shadow-lg backdrop-blur">
    üìä Dashboard
  </button>
</div>
üé® Why This Looks Creative:
Gradient background: Makes the nav bar pop

Glass-effect button: Looks modern using backdrop-blur and transparency

Emoji icon: Adds a fun touch

Hover animation: Glows when hovered

‚ú® Optional (Responsive + Sticky):
Make it stick to the top:

jsx
Copy
Edit
<div className="sticky top-0 z-50 bg-gradient-to-r from-blue-600 to-blue-800 px-6 py-3 flex justify-between items-center shadow-md">
‚úÖ Next Step?
Would you like:

This button to navigate to a dashboard page?

To display stats like average scores or charts there?

Let me know and I‚Äôll help wire it up!








I want to these update 


Got it! You're looking at the Tailwind CSS utility classes in your index.css, and you want to customize the gradient colors used by:

.from-blue-600

.to-blue-800

Specifically, the image shows:

css
Copy
Edit
--tw-gradient-from: #335bb3b8; /* a bluish custom color */
--tw-gradient-to: #1eafadad;   /* a teal-like custom end */
‚úÖ Here‚Äôs Exactly What To Do:
üîß Step 1: Go to your tailwind.config.js
You‚Äôll override the default colors here.

‚úèÔ∏è Step 2: Extend Your Theme
Add a custom gradient in your extend section like this:

js
Copy
Edit
// tailwind.config.js
module.exports = {
  theme: {
    extend: {
      colors: {
        'custom-blue-start': '#335bb3b8',
        'custom-blue-end': '#1eafadad',
      },
    },
  },
};
üåÄ Step 3: Use It in Your Button/Navbar
Update your gradient classes:

jsx
Copy
Edit
<div className="bg-gradient-to-r from-custom-blue-start to-custom-blue-end px-6 py-3 flex items-center">
  <button className="text-white font-bold bg-white/10 hover:bg-white/20 px-4 py-2 rounded-lg backdrop-blur shadow-sm transition">
    üìä Dashboard
  </button>
</div>
‚úÖ Summary
You want to...	Here's what to do
Use custom gradient colors	Define them in tailwind.config.js
Use them in components	Use from-COLOR / to-COLOR with your class names
Keep it Tailwind native	‚úÖ Done with utility classes
Let me know if you want:

A shadow behind the navbar

Fixed position navbar

Dashboard routing setup

Want me to drop the full updated JSX?







/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    "./src/**/*.{js,jsx,ts,tsx}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}                     this is my current tailwind.css.config



Perfect ‚Äî thanks for sharing your current tailwind.config.js! Let‚Äôs now update it to include your custom gradient colors (from and to), just like the image you showed.

‚úÖ Update Your tailwind.config.js Like This:
js
Copy
Edit
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    "./src/**/*.{js,jsx,ts,tsx}",
  ],
  theme: {
    extend: {
      colors: {
        // Custom gradient color stops
        'custom-blue-start': '#335bb3b8',  // bluish start
        'custom-blue-end': '#1eafadad',    // teal end
      },
    },
  },
  plugins: [],
}
‚úÖ Then Use It in Your JSX Like This:
jsx
Copy
Edit
<div className="bg-gradient-to-r from-custom-blue-start to-custom-blue-end px-6 py-3 flex items-center shadow-md">
  <button className="text-white font-bold bg-white/10 hover:bg-white/20 px-4 py-2 rounded-lg backdrop-blur shadow transition-all duration-300">
    üìä Dashboard
  </button>
</div>